{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.special import logsumexp\n",
    "import pandas as pd\n",
    "class MLP():\n",
    "    \n",
    "    def __init__(self, din, dout):\n",
    "        self.W = (2 * np.random.rand(dout, din) - 1) * (np.sqrt(6) / np.sqrt(din + dout))\n",
    "        self.b = (2 * np.random.rand(dout) - 1) * (np.sqrt(6) / np.sqrt(din + dout))\n",
    "        \n",
    "    def forward(self, x): # x.shape = (batch_size, din)\n",
    "        self.x = x # Storing x for latter (backward pass)\n",
    "        return x @ self.W.T + self.b\n",
    "\n",
    "    def backward(self, gradout):\n",
    "        self.deltaW = gradout.T @ self.x\n",
    "        self.deltab = gradout.sum(0)\n",
    "        return gradout @ self.W\n",
    "    \n",
    "class SequentialNN():\n",
    "    \n",
    "    def __init__(self, blocks: list):\n",
    "        self.blocks = blocks\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block.forward(x)\n",
    "  \n",
    "        return x\n",
    "\n",
    "    def backward(self, gradout):\n",
    "        \n",
    "        for block in self.blocks[::-1]:\n",
    "            gradout = block.backward(gradout)\n",
    "            \n",
    "        return gradout\n",
    "\n",
    "class ReLU():\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def backward(self, gradout):\n",
    "        new_grad = gradout.copy()\n",
    "        new_grad[self.x < 0] = 0.\n",
    "        return new_grad\n",
    "    \n",
    "class LogSoftmax():\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x - logsumexp(x, axis=1)[..., None]\n",
    "    \n",
    "    def backward(self, gradout):\n",
    "        gradients = np.eye(self.x.shape[1])[None, ...]\n",
    "        gradients = gradients - (np.exp(self.x) / np.sum(np.exp(self.x), axis=1)[..., None])[..., None]\n",
    "        return (np.matmul(gradients, gradout[..., None]))[:, :, 0]\n",
    "    \n",
    "class NLLLoss():\n",
    "    \n",
    "    def forward(self, pred, true):\n",
    "        self.pred = pred\n",
    "        self.true = true\n",
    "        \n",
    "        loss = 0\n",
    "        for b in range(pred.shape[0]):\n",
    "            loss -= pred[b, true[b]]\n",
    "        return loss\n",
    "\n",
    "    def backward(self):\n",
    "        din = self.pred.shape[1]\n",
    "        jacobian = np.zeros((self.pred.shape[0], din))\n",
    "        for b in range(self.pred.shape[0]):\n",
    "            jacobian[b, self.true[b]] = -1\n",
    "\n",
    "        return jacobian # batch_size x din\n",
    "    \n",
    "    def __call__(self, pred, true):\n",
    "        return self.forward(pred, true)\n",
    "    \n",
    "class Optimizer():\n",
    "    \n",
    "    def __init__(self, lr, compound_nn: SequentialNN):\n",
    "        self.lr = lr\n",
    "        self.compound_nn = compound_nn\n",
    "        \n",
    "    def step(self):\n",
    "        \n",
    "        for block in self.compound_nn.blocks:\n",
    "            if block.__class__ == MLP:\n",
    "                block.W = block.W - self.lr * block.deltaW\n",
    "                block.b = block.b - self.lr * block.deltab\n",
    "                \n",
    "def train(model, optimizer, trainX, trainy, loss_fct = NLLLoss(), nb_epochs=14000, batch_size=100):\n",
    "    training_loss = []\n",
    "    for epoch in tqdm(range(nb_epochs)):\n",
    "\n",
    "        # Sample batch size\n",
    "        batch_idx = [np.random.randint(0, trainX.shape[0]) for _ in range(batch_size)]\n",
    "        x = trainX[batch_idx]\n",
    "        target = trainy[batch_idx]\n",
    "\n",
    "        prediction = model.forward(x) # Forward pass\n",
    "        loss_value = loss_fct(prediction, target) # Compute the loss\n",
    "        training_loss.append(loss_value) # Log loss\n",
    "        gradout = loss_fct.backward()\n",
    "        model.backward(gradout) # Backward pass\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "    return training_loss\n",
    "\n",
    "def onehot_encoder(ary, columns=[], remove_trap=False):\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    # Iterate each column in DataFrame ary\n",
    "    for i in range(ary.shape[1]):\n",
    "        # if this column (i) is dummy column\n",
    "        if i in columns:\n",
    "            base_name = ary.columns[i]\n",
    "            this_column = pd.get_dummies(ary.iloc[:, i])\n",
    "            this_column = this_column.rename(columns={n:\"{}_{}\".format(base_name, n) for n in this_column.columns})\n",
    "            # Remove Dummy Variable Trap if needed\n",
    "            if remove_trap:\n",
    "                this_column = this_column.drop(this_column.columns[0], axis=1)\n",
    "        # else this column is normal column\n",
    "        else:\n",
    "            this_column = ary.iloc[:, i]\n",
    "        # Append this column to the Result DataFrame\n",
    "        df_results = pd.concat([df_results, this_column], axis=1)\n",
    "\n",
    "    return df_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 34)\n",
      "(39063, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14000/14000 [01:47<00:00, 130.63it/s]\n",
      "100%|██████████| 14000/14000 [01:18<00:00, 179.38it/s]\n",
      "100%|██████████| 14000/14000 [00:55<00:00, 253.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy: 61.605917294540056 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    # Load and process data\n",
    "    train_df = pd.read_csv('./train_preproceed.csv')\n",
    "    test_df = pd.read_csv('./test.csv')\n",
    "    train_df = train_df.sample(n=1000, random_state=42)  # 使用 random_state 以确保可重复性\n",
    "    test_df['volume'] = np.log(test_df.length.astype('int64') * test_df.width * test_df.height * 1e-6)\n",
    "    test_df = test_df[['volume', 'area_cluster','model','age_of_car','age_of_policyholder','policy_tenure']]\n",
    "    \n",
    "    train_df = onehot_encoder(train_df, columns=[1, 2], remove_trap=True)\n",
    "    test_df = onehot_encoder(test_df, columns=[1, 2], remove_trap=True)    \n",
    "    X = train_df.iloc[:, :-1].values\n",
    "    Y = train_df.iloc[:, -1].values.reshape(-1,1)\n",
    "    \n",
    "    print(X.shape)\n",
    "    print(X_test.shape)\n",
    "    \n",
    "    mlp = SequentialNN([MLP(34, 128), ReLU(), \n",
    "                        MLP(128, 64), ReLU(), \n",
    "                        MLP(64, 2), LogSoftmax()])\n",
    "    \n",
    "    optimizer = Optimizer(1e-3, mlp)\n",
    "    \n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42) \n",
    "    \n",
    "    accuracies = []  # 存储每个fold的准确度\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "        \n",
    "        training_loss = train(mlp, optimizer, X_train, Y_train)\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        accuracy = 0\n",
    "        for i in range(X_val.shape[0]):\n",
    "            prediction = mlp.forward(X_val[i].reshape(1, 34)).argmax()\n",
    "            if prediction == Y_val[i]:\n",
    "                accuracy += 1\n",
    "        val_accuracy = accuracy / X_val.shape[0] * 100\n",
    "        accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Calculate average accuracy over all folds\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    print('Average validation accuracy:', average_accuracy, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 34)\n",
      "(39063, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14000/14000 [01:00<00:00, 229.53it/s]\n",
      "100%|██████████| 14000/14000 [01:02<00:00, 225.52it/s]\n",
      "100%|██████████| 14000/14000 [01:17<00:00, 181.37it/s]\n",
      "100%|██████████| 14000/14000 [01:49<00:00, 127.96it/s]\n",
      "100%|██████████| 14000/14000 [01:06<00:00, 211.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy: 63.4 %\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    # Load and process data\n",
    "    train_df = pd.read_csv('./train_preproceed.csv')\n",
    "    test_df = pd.read_csv('./test.csv')\n",
    "    train_df = train_df.sample(n=1000, random_state=42)  # 使用 random_state 以确保可重复性\n",
    "    test_df['volume'] = np.log(test_df.length.astype('int64') * test_df.width * test_df.height * 1e-6)\n",
    "    test_df = test_df[['volume', 'area_cluster','model','age_of_car','age_of_policyholder','policy_tenure']]\n",
    "    \n",
    "    train_df = onehot_encoder(train_df, columns=[1, 2], remove_trap=True)\n",
    "    test_df = onehot_encoder(test_df, columns=[1, 2], remove_trap=True)\n",
    "    X = train_df.iloc[:, :-1].values\n",
    "    Y = train_df.iloc[:, -1].values.reshape(-1,1)\n",
    "    \n",
    "    print(X.shape)\n",
    "    print(X_test.shape)\n",
    "    \n",
    "    mlp = SequentialNN([MLP(34, 128), ReLU(), \n",
    "                        MLP(128, 64), ReLU(), \n",
    "                        MLP(64, 2), LogSoftmax()])\n",
    "    \n",
    "    optimizer = Optimizer(1e-3, mlp)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42) \n",
    "    \n",
    "    accuracies = []  # 存储每个fold的准确度\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "        \n",
    "        training_loss = train(mlp, optimizer, X_train, Y_train)\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        accuracy = 0\n",
    "        for i in range(X_val.shape[0]):\n",
    "            prediction = mlp.forward(X_val[i].reshape(1, 34)).argmax()\n",
    "            if prediction == Y_val[i]:\n",
    "                accuracy += 1\n",
    "        val_accuracy = accuracy / X_val.shape[0] * 100\n",
    "        accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Calculate average accuracy over all folds\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    print('Average validation accuracy:', average_accuracy, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 34)\n",
      "(39063, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14000/14000 [01:04<00:00, 216.45it/s]\n",
      "100%|██████████| 14000/14000 [00:54<00:00, 255.17it/s]\n",
      "100%|██████████| 14000/14000 [00:44<00:00, 312.21it/s]\n",
      "100%|██████████| 14000/14000 [00:44<00:00, 317.35it/s]\n",
      "100%|██████████| 14000/14000 [00:39<00:00, 358.56it/s]\n",
      "100%|██████████| 14000/14000 [01:11<00:00, 195.74it/s]\n",
      "100%|██████████| 14000/14000 [01:30<00:00, 154.24it/s]\n",
      "100%|██████████| 14000/14000 [01:02<00:00, 222.97it/s]\n",
      "100%|██████████| 14000/14000 [01:00<00:00, 232.45it/s]\n",
      "100%|██████████| 14000/14000 [00:53<00:00, 263.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy: 72.4 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    # Load and process data\n",
    "    train_df = pd.read_csv('./train_preproceed.csv')\n",
    "    test_df = pd.read_csv('./test.csv')\n",
    "    train_df = train_df.sample(n=1000, random_state=42)  # 使用 random_state 以确保可重复性\n",
    "    test_df['volume'] = np.log(test_df.length.astype('int64') * test_df.width * test_df.height * 1e-6)\n",
    "    test_df = test_df[['volume', 'area_cluster','model','age_of_car','age_of_policyholder','policy_tenure']]\n",
    "    \n",
    "    train_df = onehot_encoder(train_df, columns=[1, 2], remove_trap=True)\n",
    "    test_df = onehot_encoder(test_df, columns=[1, 2], remove_trap=True)\n",
    "    X = train_df.iloc[:, :-1].values\n",
    "    Y = train_df.iloc[:, -1].values.reshape(-1,1)\n",
    "    \n",
    "    print(X.shape)\n",
    "    print(X_test.shape)\n",
    "    \n",
    "    mlp = SequentialNN([MLP(34, 128), ReLU(), \n",
    "                        MLP(128, 64), ReLU(), \n",
    "                        MLP(64, 2), LogSoftmax()])\n",
    "    \n",
    "    optimizer = Optimizer(1e-3, mlp)\n",
    "    \n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42) \n",
    "    \n",
    "    accuracies = []  # 存储每个fold的准确度\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "        \n",
    "        training_loss = train(mlp, optimizer, X_train, Y_train)\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        accuracy = 0\n",
    "        for i in range(X_val.shape[0]):\n",
    "            prediction = mlp.forward(X_val[i].reshape(1, 34)).argmax()\n",
    "            if prediction == Y_val[i]:\n",
    "                accuracy += 1\n",
    "        val_accuracy = accuracy / X_val.shape[0] * 100\n",
    "        accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Calculate average accuracy over all folds\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    print('Average validation accuracy:', average_accuracy, '%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
