{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "def onehot_encoder(ary, columns=[], remove_trap=False):\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    # Iterate each column in DataFrame ary\n",
    "    for i in range(ary.shape[1]):\n",
    "        # if this column (i) is dummy column\n",
    "        if i in columns:\n",
    "            base_name = ary.columns[i]\n",
    "            this_column = pd.get_dummies(ary.iloc[:, i])\n",
    "            this_column = this_column.rename(columns={n:\"{}_{}\".format(base_name, n) for n in this_column.columns})\n",
    "            # Remove Dummy Variable Trap if needed\n",
    "            if remove_trap:\n",
    "                this_column = this_column.drop(this_column.columns[0], axis=1)\n",
    "        # else this column is normal column\n",
    "        else:\n",
    "            this_column = ary.iloc[:, i]\n",
    "        # Append this column to the Result DataFrame\n",
    "        df_results = pd.concat([df_results, this_column], axis=1)\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function that calculates the distance between points\n",
    "def euclid_distance(l1: List[float], l2: List[float]) -> float:\n",
    "    assert len(l1) == len(l2)\n",
    "    return sum([(l1_i - l2_i)**2 for l1_i, l2_i in zip(l1, l2)])**0.5\n",
    "\n",
    "def max_norm_distance(l1: List[float], l2: List[float]) -> float:\n",
    "    assert len(l1) == len(l2)\n",
    "    return max(abs(l1_i - l2_i) for l1_i, l2_i in zip(l1, l2))\n",
    "\n",
    "def manhattan_distance(l1: List[float], l2: List[float]) -> float:\n",
    "    assert len(l1) == len(l2)\n",
    "    return sum(abs(l1_i - l2_i) for l1_i, l2_i in zip(l1, l2))\n",
    "\n",
    "#Search function for the most frequent sample value\n",
    "def most_frequent(l: List[str]) -> str:\n",
    "    count = {}\n",
    "    for l_i in l:\n",
    "        if l_i in count.keys():\n",
    "            count[l_i] += 1\n",
    "        else:\n",
    "            count[l_i] = 1\n",
    "    count = sorted(count.items(), key = lambda item: item[1], reverse = True)\n",
    "    return count[0][0]\n",
    "\n",
    "#Classification function\n",
    "def classification(data: List, df: pd.DataFrame, k: int, distance:str) -> str:\n",
    "    dist = []\n",
    "    if distance=='euclid_distance':\n",
    "        #Calculation of distances to each point of the training sample\n",
    "        for i in range(df.shape[0]):\n",
    "            dist.append((i, euclid_distance(data, df.iloc[i, :-1])))\n",
    "    elif distance=='max_norm_distance':\n",
    "        #Calculation of distances to each point of the training sample\n",
    "        for i in range(df.shape[0]):\n",
    "            dist.append((i, max_norm_distance(data, df.iloc[i, :-1])))\n",
    "    elif distance=='manhattan_distance':\n",
    "        #Calculation of distances to each point of the training sample\n",
    "        for i in range(df.shape[0]):\n",
    "            dist.append((i, manhattan_distance(data, df.iloc[i, :-1])))\n",
    "        \n",
    "    #Search for values of the target variable\n",
    "    dist.sort(key = lambda item: item[1])\n",
    "    values = [df.iloc[d[0], -1] for d in dist[:k]]\n",
    "    \n",
    "    return most_frequent(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.556\n",
      "0.578\n",
      "0.5609999999999999\n",
      "My algorithm's average accuracy using euclid_distance : 0.556\n",
      "My algorithm's average accuracy using max_norm_distance : 0.578\n",
      "My algorithm's average accuracy using manhattan_distance : 0.5609999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "train_df = pd.read_csv('./train_preproceed.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_df_ = onehot_encoder(train_df, columns=[1, 2], remove_trap=True)\n",
    "train_df = train_df_.sample(n=1000, random_state=42)  # 使用 random_state 以确保可重复性\n",
    "X_train = train_df.iloc[:, :-1].values\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "Y_train = train_df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "val_df = train_df_.sample(n=1000, random_state=38)  # 使用 random_state 以确保可重复性\n",
    "X_test = val_df.iloc[:, :-1].values\n",
    "X_test= scaler.fit_transform(X_test)\n",
    "Y_test = val_df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)  # 将n_splits设置为您希望的折数\n",
    "accuracy_results = []\n",
    "\n",
    "distance = ['euclid_distance', 'max_norm_distance', 'manhattan_distance']\n",
    "\n",
    "for j in range(len(distance)):\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_df):\n",
    "        train_set, test_set = train_df.iloc[train_index], train_df.iloc[test_index]\n",
    "        \n",
    "        X_train = train_set.iloc[:, :-1].values\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        Y_train = train_set.iloc[:, -1].values.reshape(-1, 1)\n",
    "        \n",
    "        X_test = test_set.iloc[:, :-1].values\n",
    "        X_test = scaler.transform(X_test)  # 使用相同的缩放\n",
    "        \n",
    "        my_pred = [classification(test_set.iloc[i, :-1], train_set, 3, distance[j]) for i in range(test_set.shape[0])]\n",
    "        l = [(test_set.iloc[i, -1], my_pred[i]) for i in range(test_set.shape[0])]\n",
    "        accuracy = sum([test == pred for test, pred in l]) / len(l)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    accuracy_results.append(avg_accuracy)\n",
    "    print(avg_accuracy)\n",
    "for j in range(len(distance)):\n",
    "    print('My algorithm\\'s average accuracy using', distance[j], ':', accuracy_results[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5580340819861779\n",
      "0.5650350949752148\n",
      "0.5620231009452566\n",
      "My algorithm's average accuracy using euclid_distance : 0.5580340819861779\n",
      "My algorithm's average accuracy using max_norm_distance : 0.5650350949752148\n",
      "My algorithm's average accuracy using manhattan_distance : 0.5620231009452566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "train_df = pd.read_csv('./train_preproceed.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_df_ = onehot_encoder(train_df, columns=[1, 2], remove_trap=True)\n",
    "train_df = train_df_.sample(n=1000, random_state=42)  # 使用 random_state 以确保可重复性\n",
    "X_train = train_df.iloc[:, :-1].values\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "Y_train = train_df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "val_df = train_df_.sample(n=1000, random_state=38)  # 使用 random_state 以确保可重复性\n",
    "X_test = val_df.iloc[:, :-1].values\n",
    "X_test= scaler.fit_transform(X_test)\n",
    "Y_test = val_df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)  # 将n_splits设置为您希望的折数\n",
    "accuracy_results = []\n",
    "\n",
    "distance = ['euclid_distance', 'max_norm_distance', 'manhattan_distance']\n",
    "\n",
    "for j in range(len(distance)):\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_df):\n",
    "        train_set, test_set = train_df.iloc[train_index], train_df.iloc[test_index]\n",
    "        \n",
    "        X_train = train_set.iloc[:, :-1].values\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        Y_train = train_set.iloc[:, -1].values.reshape(-1, 1)\n",
    "        \n",
    "        X_test = test_set.iloc[:, :-1].values\n",
    "        X_test = scaler.transform(X_test)  # 使用相同的缩放\n",
    "        \n",
    "        my_pred = [classification(test_set.iloc[i, :-1], train_set, 3, distance[j]) for i in range(test_set.shape[0])]\n",
    "        l = [(test_set.iloc[i, -1], my_pred[i]) for i in range(test_set.shape[0])]\n",
    "        accuracy = sum([test == pred for test, pred in l]) / len(l)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    accuracy_results.append(avg_accuracy)\n",
    "    print(avg_accuracy)\n",
    "for j in range(len(distance)):\n",
    "    print('My algorithm\\'s average accuracy using', distance[j], ':', accuracy_results[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.583\n",
      "0.59\n",
      "0.582\n",
      "My algorithm's average accuracy using euclid_distance : 0.583\n",
      "My algorithm's average accuracy using max_norm_distance : 0.59\n",
      "My algorithm's average accuracy using manhattan_distance : 0.582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "train_df = pd.read_csv('./train_preproceed.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_df_ = onehot_encoder(train_df, columns=[1, 2], remove_trap=True)\n",
    "train_df = train_df_.sample(n=1000, random_state=42)  # 使用 random_state 以确保可重复性\n",
    "X_train = train_df.iloc[:, :-1].values\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "Y_train = train_df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "val_df = train_df_.sample(n=1000, random_state=38)  # 使用 random_state 以确保可重复性\n",
    "X_test = val_df.iloc[:, :-1].values\n",
    "X_test= scaler.fit_transform(X_test)\n",
    "Y_test = val_df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 将n_splits设置为您希望的折数\n",
    "accuracy_results = []\n",
    "\n",
    "distance = ['euclid_distance', 'max_norm_distance', 'manhattan_distance']\n",
    "\n",
    "for j in range(len(distance)):\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_df):\n",
    "        train_set, test_set = train_df.iloc[train_index], train_df.iloc[test_index]\n",
    "        \n",
    "        X_train = train_set.iloc[:, :-1].values\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        Y_train = train_set.iloc[:, -1].values.reshape(-1, 1)\n",
    "        \n",
    "        X_test = test_set.iloc[:, :-1].values\n",
    "        X_test = scaler.transform(X_test)  # 使用相同的缩放\n",
    "        \n",
    "        my_pred = [classification(test_set.iloc[i, :-1], train_set, 3, distance[j]) for i in range(test_set.shape[0])]\n",
    "        l = [(test_set.iloc[i, -1], my_pred[i]) for i in range(test_set.shape[0])]\n",
    "        accuracy = sum([test == pred for test, pred in l]) / len(l)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    accuracy_results.append(avg_accuracy)\n",
    "    print(avg_accuracy)\n",
    "for j in range(len(distance)):\n",
    "    print('My algorithm\\'s average accuracy using', distance[j], ':', accuracy_results[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5880000000000001\n",
      "0.599\n",
      "0.583\n",
      "My algorithm's average accuracy using euclid_distance : 0.5880000000000001\n",
      "My algorithm's average accuracy using max_norm_distance : 0.599\n",
      "My algorithm's average accuracy using manhattan_distance : 0.583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "train_df = pd.read_csv('./train_preproceed.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_df_ = onehot_encoder(train_df, columns=[1, 2], remove_trap=True)\n",
    "train_df = train_df_.sample(n=1000, random_state=42)  # 使用 random_state 以确保可重复性\n",
    "X_train = train_df.iloc[:, :-1].values\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "Y_train = train_df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "val_df = train_df_.sample(n=1000, random_state=38)  # 使用 random_state 以确保可重复性\n",
    "X_test = val_df.iloc[:, :-1].values\n",
    "X_test= scaler.fit_transform(X_test)\n",
    "Y_test = val_df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)  # 将n_splits设置为您希望的折数\n",
    "accuracy_results = []\n",
    "\n",
    "distance = ['euclid_distance', 'max_norm_distance', 'manhattan_distance']\n",
    "\n",
    "for j in range(len(distance)):\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_df):\n",
    "        train_set, test_set = train_df.iloc[train_index], train_df.iloc[test_index]\n",
    "        \n",
    "        X_train = train_set.iloc[:, :-1].values\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        Y_train = train_set.iloc[:, -1].values.reshape(-1, 1)\n",
    "        \n",
    "        X_test = test_set.iloc[:, :-1].values\n",
    "        X_test = scaler.transform(X_test)  # 使用相同的缩放\n",
    "        \n",
    "        my_pred = [classification(test_set.iloc[i, :-1], train_set, 3, distance[j]) for i in range(test_set.shape[0])]\n",
    "        l = [(test_set.iloc[i, -1], my_pred[i]) for i in range(test_set.shape[0])]\n",
    "        accuracy = sum([test == pred for test, pred in l]) / len(l)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    accuracy_results.append(avg_accuracy)\n",
    "    print(avg_accuracy)\n",
    "for j in range(len(distance)):\n",
    "    print('My algorithm\\'s average accuracy using', distance[j], ':', accuracy_results[j])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
