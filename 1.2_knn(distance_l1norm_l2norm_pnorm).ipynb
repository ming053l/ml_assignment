{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "def onehot_encoder(ary, columns=[], remove_trap=False):\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    # Iterate each column in DataFrame ary\n",
    "    for i in range(ary.shape[1]):\n",
    "        # if this column (i) is dummy column\n",
    "        if i in columns:\n",
    "            base_name = ary.columns[i]\n",
    "            this_column = pd.get_dummies(ary.iloc[:, i])\n",
    "            this_column = this_column.rename(columns={n:\"{}_{}\".format(base_name, n) for n in this_column.columns})\n",
    "            # Remove Dummy Variable Trap if needed\n",
    "            if remove_trap:\n",
    "                this_column = this_column.drop(this_column.columns[0], axis=1)\n",
    "        # else this column is normal column\n",
    "        else:\n",
    "            this_column = ary.iloc[:, i]\n",
    "        # Append this column to the Result DataFrame\n",
    "        df_results = pd.concat([df_results, this_column], axis=1)\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function that calculates the distance between points\n",
    "def euclid_distance(l1: List[float], l2: List[float]) -> float:\n",
    "    assert len(l1) == len(l2)\n",
    "    return sum([(l1_i - l2_i)**2 for l1_i, l2_i in zip(l1, l2)])**0.5\n",
    "\n",
    "def max_norm_distance(l1: List[float], l2: List[float]) -> float:\n",
    "    assert len(l1) == len(l2)\n",
    "    return max(abs(l1_i - l2_i) for l1_i, l2_i in zip(l1, l2))\n",
    "\n",
    "def manhattan_distance(l1: List[float], l2: List[float]) -> float:\n",
    "    assert len(l1) == len(l2)\n",
    "    return sum(abs(l1_i - l2_i) for l1_i, l2_i in zip(l1, l2))\n",
    "\n",
    "#Search function for the most frequent sample value\n",
    "def most_frequent(l: List[str]) -> str:\n",
    "    count = {}\n",
    "    for l_i in l:\n",
    "        if l_i in count.keys():\n",
    "            count[l_i] += 1\n",
    "        else:\n",
    "            count[l_i] = 1\n",
    "    count = sorted(count.items(), key = lambda item: item[1], reverse = True)\n",
    "    return count[0][0]\n",
    "\n",
    "#Classification function\n",
    "def classification(data: List, df: pd.DataFrame, k: int, distance:str) -> str:\n",
    "    dist = []\n",
    "    if distance=='euclid_distance':\n",
    "        #Calculation of distances to each point of the training sample\n",
    "        for i in range(df.shape[0]):\n",
    "            dist.append((i, euclid_distance(data, df.iloc[i, :-1])))\n",
    "    elif distance=='max_norm_distance':\n",
    "        #Calculation of distances to each point of the training sample\n",
    "        for i in range(df.shape[0]):\n",
    "            dist.append((i, max_norm_distance(data, df.iloc[i, :-1])))\n",
    "    elif distance=='manhattan_distance':\n",
    "        #Calculation of distances to each point of the training sample\n",
    "        for i in range(df.shape[0]):\n",
    "            dist.append((i, manhattan_distance(data, df.iloc[i, :-1])))\n",
    "        \n",
    "    #Search for values of the target variable\n",
    "    dist.sort(key = lambda item: item[1])\n",
    "    values = [df.iloc[d[0], -1] for d in dist[:k]]\n",
    "    \n",
    "    return most_frequent(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My algorithm's accuracy: 0.587 euclid_distance\n",
      "My algorithm's accuracy: 0.593 max_norm_distance\n",
      "My algorithm's accuracy: 0.592 manhattan_distance\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./train_preproceed.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "test_df['volume'] = np.log(test_df.length.astype('int64') * test_df.width * test_df.height * 1e-6)\n",
    "test_df = test_df[['volume', 'area_cluster','model','age_of_car','age_of_policyholder','policy_tenure']]\n",
    "\n",
    "train_df_ = onehot_encoder(train_df, columns=[1, 2], remove_trap=True)\n",
    "#test_df = onehot_encoder(test_df, columns=[1, 2], remove_trap=True)\n",
    "train_df = train_df_.sample(n=1000, random_state=42)  # 使用 random_state 以确保可重复性\n",
    "X_train = train_df.iloc[:, :-1].values\n",
    "\n",
    "\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "\n",
    "Y_train = train_df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "val_df = train_df_.sample(n=1000, random_state=38)  # 使用 random_state 以确保可重复性\n",
    "\n",
    "\n",
    "X_test = val_df.iloc[:, :-1].values\n",
    "X_test= scaler.fit_transform(X_test)\n",
    "\n",
    "Y_test = val_df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "distance=['euclid_distance','max_norm_distance','manhattan_distance']\n",
    "for j in range(len(distance)):\n",
    "    my_pred = [classification(val_df.iloc[i, :-1], train_df, 3, distance[j]) for i in range(val_df.shape[0])]\n",
    "    l = [(val_df.iloc[i, -1], my_pred[i]) for i in range(val_df.shape[0])]\n",
    "    print('My algorithm\\'s accuracy:', sum([test == pred for test, pred in l]) / len(l), distance[j])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
